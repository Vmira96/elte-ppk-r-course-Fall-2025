---
title: "Assignment 3: Model comparison"
author: "Marton Kovacs"
output: html_document
editor_options: 
  chunk_output_type: console
---

In this lab assignment you are going to work with (simulated) data related to perioperative pain and its psychological and hormonal predictors. In the assignment you will assess the added benefit of including some psychological and hormonal predictors to the already established demographic predictors of pain.

In this assignment you will set up a hierarchical regression model to predict postoperative pain after wisdom tooth surgery. 

# Research problem

The amount of pain experienced around and after surgeries are highly variable between and within individuals. In order to improve surgical pain management regimens we need to understand what influences pain around surgical procedures and predict the amount of pain an individual will experience.

Your first study in this area is related to assessing the influence of trait and state psychological measures on pain, and to see whether taking into account these variables can improve our understanding of postoperative pain.

# Procedures and measures

Use the data file called ‚Äòassignment_3_dataset‚Äô, from the 'data/' folder.

You have collected data from 160 adults who were scheduled to undergo surgical extraction of the third mandibular molar (wisdom tooth surgery). Patients filled out a form in the waiting room before their surgery. The form contained questions about their sex, age, and weight, and psychological questionnaires assessing anxiety, pain catastrophizing, and mindfulness (see descriptions below). You also got blood samples and saliva samples from participants in the waiting room 5 minutes before their operations to determine the serum (a component of the blood) and salivary cortisol levels of participants. Participants were contacted 5 hours after the surgery to see how much pain they were experiencing. The __level of pain__ at that moment was recorded using a numerical rating scale using a __scale of 0 to 10__, where 0 means ‚Äúno pain‚Äù and 10 means ‚Äúworst pain I can imagine‚Äù. 

__The State Trait Anxiety Inventory:__ T measures trait anxiety on a scale of 20 to 80, higher scores mean higher anxiety. Anxiety has been found in many studies to positively correlate with the level of pain experienced. This is __variable STAI_trait__ in the dataset.

__The Pain Catastrophizing Scale__ measures the extent of pain catastrophizing, which is characterized by a tendency to magnify the threat value of a pain stimulus and to feel helpless in the presence of pain, as well as by a relative inability to prevent or inhibit pain-related thoughts in anticipation of, during, or following a painful event. The total score on this scale ranges from 0 to 52, higher scores mean higher catastrophizing. Pain catastrophizing is one of the well-established predictors of clinical pain. This is __variable pain_cat__ in the dataset.

__The Mindful Attention Awareness Scale (MAAS)__ measures dispositional mindfulness, which may be described as a tendency to turn attention to present-moment experiences in an open, non-judgmental way. The MAAS total score ranges from 1 to 6 (an average of the item scores), with higher scores representing higher dispositional mindfulness. Trait mindfulness has been theorized to serve as a protective factor against pain, as the individual would be more objective about their pain experience and tend to associate less discomfort, despair, and hopelessness to the pain-related sensations. This is __variable mindfulness__ in the dataset.

__Cortisol__ is a stress hormone associated with acute and chronic stress. Cortisol levels are thought to be positively associated with pain experience. Cortisol can be __measured from both blood and the saliva__, although, serum cortisol is often regarded in medical research as more reliably related to stress (serum is a component of the blood plasma). These are __variables cortisol_serum__, and __cortisol_saliva__ in the dataset.

# Research question

Previous studies and meta-analyses showed that age and sex are often predictors of pain (age is negatively associated with pain, while sex is a predictor more dependent on the type of the procedure). You would like to determine the extent to which taking into account psychological and hormonal variables aside from the already used demographic variables would improve our understanding of postoperative pain.

To answer this research question you will __need to compare two models__ (with a hierarchical regression). The __simpler model__ should contain __age and sex as predictors of pain__, while the __more complex model__ should contain the __predictors: age, sex, STAI, pain catastrophizing, mindfulness, and cortisol measures__. Notice that the predictors used in the simpler model are a subset of the predictors used in more complex model. __You will have to do model comparison to assess whether substantial new information was gained about pain in the more complex model compared to the simpler model.__  

# What to report

As usual, before you can interpret your model, you will need to run data and model diagnostics. First, check the variables included in the more complex model (age, sex, STAI, pain catastrophizing, mindfulness, and cortisol measures as predictors, and pain as an outcome) for __coding errors__, and the model itself for __influential outliers__ (for example using Cook‚Äôs distance). Furthermore, check the final model to see if the __assumptions of linear regression hold true__, that is, __normality__ (of the residuals), __linearity__ (of the relationship), __homogeneity of variance__ (also called homoscedasticity) and that there is no excess __multicollinearity__ (‚Äúuncorrelated predictors‚Äù in Navarro‚Äôs words). If you find anything amiss during these checks, make the appropriate decision or correction and report your findings and actions in your report. 

__Note:__ If you do any changes, such as exclude cases, or exclude predictors from the model, you will have to re-run the above checks for your final data and model.

Report the results of the simpler model and the more complex model. For both models you should report the model test statistics (adj.R2, F, df, and p value). Also, report the statistics describing the coefficients of the predictors in a table format (unstandardized regression coefficients and 95% confidence intervals, standardized regression coefficients (B and Beta values), and p values).

Write up the regression equation of the more complex model in the form of ùëå = ùëè0 + ùëè1 ‚àó X1 + ùëè2 ‚àó X2 +‚Ä¶+ bn * Xn, in which you use the actual regression coefficients of your models. (b0 stands for the intercept and b1, b2 ‚Ä¶ bn stand for the model coefficients for each of the predictors, and X1, X2, ‚Ä¶ Xn denote the predictors).

Compare the two models in terms of how much variance they explain of pain‚Äôs variability in the sample. Report Akaike information criterion (AIC) for both models and the F test statistic and p value of the likelihood ratio test comparing the two models.

# What to discuss

In your discussion of the findings, briefly interpret the results of the above analyses, and indicate whether you think that anything was gained by including the psychological and hormone measures in the model.

# Solution

## Read the data

Read the dataset used in this assignment. Pay attention to the extension of the datafile.

```{r}
library(tidyverse)
library(broom)      
library(car)         
library(lmtest)   
library(readxl)

knitr::opts_chunk$set(echo = TRUE)
data <- read_excel("data/assignment_3_dataset.xlsx")
``` 

## Data and model diagnostics 
### Data diagnostics
#### Descriptives of the variables

Run an exploratory data analysis (EDA) to investigate the dataset.

```{r}
# Descriptives of the variables
summary(data)
glimpse(data)

# Distribution of main variables
data %>%
  select(pain, age, STAI_trait, pain_cat, cortisol_serum, cortisol_saliva,
         mindfulness, weight, IQ, household_income) %>%
  gather(key = "variable", value = "value") %>%
  ggplot(aes(x = value)) +
  geom_histogram(bins = 30) +
  facet_wrap(~ variable, scales = "free") +
  theme_minimal()

# Distribution of categorical variables
table(data$sex)

ggplot(data, aes(x = sex)) +
  geom_bar() +
  theme_minimal()

#Correlation matrix
numeric_vars <- data %>% 
  select_if(is.numeric)

cor(numeric_vars)

library(corrplot)
corrplot(cor(numeric_vars), method = "color")

# Correlations between main variables
## Pain vs age
ggplot(data, aes(x = age, y = pain)) +
  geom_point() +
  geom_smooth(method = "lm") +
  theme_minimal()

## Pain vs sex
ggplot(data, aes(x = sex, y = pain)) +
  geom_boxplot() +
  theme_minimal()
```

#Descriptives of the variables

The dataset contains data from 160 participants. There are no missing values in any variable.

Pain has a mean of ~5.19 (SD ~2), with a minimum of 1 and a maximum of 50, suggesting that a few participants reported unusually high pain values. Most values fall between 4 and 6.

Sex is approximately evenly distributed (male n = 76, female n = 84).

Age ranges from 24 to 53, with an average of 40.7 years, indicating a mid-adult sample.

The psychological variables show the following tendencies:

STAI_trait: mean ‚âà 40, moderate anxiety levels.

pain_cat: mean ‚âà 29.9, moderate pain catastrophizing.

mindfulness: mean ‚âà 3.2 on a 1‚Äì6 scale, indicating a mid-range mindfulness tendency.

Biological stress markers:

cortisol_serum and cortisol_saliva show moderate ranges and are very strongly correlated (r ‚âà .91), as expected from two measures of the same hormone.

Socioeconomic variables:

household_income ranges widely (5,548 ‚Äì 139,268), showing large variability.

Weight ranges from 33.8 kg to 97.1 kg. IQ ranges from 52 to 144, with a mean around 100, consistent with a general population sample.

Distributions

Histograms show that most variables are approximately normally distributed, with slight skewness in:

household_income (right-skewed)

pain (a few extreme high values)

cortisol measures (slightly right-skewed)

Correlations

Key relationships:

Serum and saliva cortisol have an extremely high correlation (r = .91).

STAI_trait, pain_cat, and both cortisol measures form a cluster of positively correlated variables.

Mindfulness correlates negatively with psychological distress variables (STAI_trait: r ‚âà ‚Äì.48, pain_cat: r ‚âà ‚Äì.50).

Pain shows small-to-moderate positive correlations with psychological variables and cortisol.

Age is weakly negatively correlated with pain.

Pain relationships

Pain ~ age: The scatterplot indicates no strong linear relationship, with a slight trend toward lower pain in older participants.

Pain ~ sex: Boxplots show very similar pain levels in males and females.

#### Correct coding errors

If you find values in the dataset during the EDA, that are not correct based on the provided descriptions of the variables of the dataset please correct them here.

```{r}
data <- data %>%
  mutate(sex = ifelse(sex == "woman", "female", sex))
data$sex <- factor(data$sex, levels = c("male", "female"))
```
During the EDA, one miscoded value was found in the variable sex.
The category ‚Äúwoman‚Äù appeared once, even though the dataset documentation indicates that the variable should contain only ‚Äúmale‚Äù and ‚Äúfemale‚Äù.
This value was corrected by recoding ‚Äúwoman‚Äù to ‚Äúfemale‚Äù, and afterward the variable was refactored to ensure correct level order.

### Model diagnostics
#### Build the more complex model

In order to test the more complex model for outliers and to test the assumptions first build the model.

```{r}
# Complex model
model_complex <- lm(
  pain ~ age + sex + STAI_trait + pain_cat + cortisol_serum +
    cortisol_saliva + mindfulness + weight + IQ + household_income,
  data = data
)
summary(model_complex)
```
# Model Summary

A multiple linear regression was conducted to examine the relationship between pain and a set of predictors, including age, sex, STAI_trait, pain_cat, cortisol_serum, cortisol_saliva, mindfulness, weight, IQ, and household_income.
The model summary indicates the following:

Residuals range from -3.877 to 43.058, with a median of -0.213, suggesting that most residuals are close to zero but there are some large deviations, indicating potential outliers.

Multiple R-squared = 0.097 and Adjusted R-squared = 0.037, which means the model explains approximately 9.7% of the variance in pain, and the adjusted value accounting for the number of predictors is only 3.7%. This indicates a low explanatory power.

F-statistic = 1.604 (p = 0.111) suggests that the model, as a whole, is not statistically significant, meaning the predictors collectively do not significantly explain variability in pain.

Individual predictors all have p-values greater than 0.05, indicating that none of the variables significantly predict pain in this model. The largest t-values are observed for cortisol_saliva (t = 1.366) and IQ (t = 1.347), though these are still not significant.

Interpretation:
The current model shows limited explanatory power, and the presence of large residuals suggests that there may be influential points or outliers affecting the estimates. Therefore, the next step is to perform outlier diagnostics, including Cook‚Äôs distance, leverage, and standardized residuals, to identify and potentially address any data points that have a disproportionate influence on the model.

#### Checking for influential outliers

Check for outlier values in the model.

```{r}
# Cook's distance
cooksd <- cooks.distance(model_complex)
plot(cooksd, type = "h", main = "Cook's Distance", ylab = "Cook's distance")
abline(h = 4/(nrow(data)-length(model_complex$coefficients)-2), col = "red") 
# Points above the red line are considered influential

# Leverage (hat values)
lev <- hatvalues(model_complex)
plot(lev, type = "h", main = "Leverage Values", ylab = "Leverage")
abline(h = 2*length(model_complex$coefficients)/nrow(data), col = "red")
# Points above the red line have high leverage

# Standardized residuals
std_res <- rstandard(model_complex)
plot(std_res, type = "h", main = "Standardized Residuals", ylab = "Standardized Residuals")
abline(h = c(-3, 3), col = "red")

# Thresholds
cooks_threshold <- 4/(nrow(data) - length(model_complex$coefficients) - 2)
leverage_threshold <- 2*length(model_complex$coefficients)/nrow(data)
residual_threshold <- 3  # standardized residuals beyond ¬±3

# Points exceeding thresholds
influential_cooks <- which(cooks.distance(model_complex) > cooks_threshold)
high_leverage <- which(hatvalues(model_complex) > leverage_threshold)
extreme_resid <- which(abs(rstandard(model_complex)) > residual_threshold)

# Print results
cat("Observations with high Cook's distance:", influential_cooks, "\n")
cat("Observations with high leverage:", high_leverage, "\n")
cat("Observations with extreme standardized residuals:", extreme_resid, "\n")
```
Identification of Influential Outliers

The model was further examined to identify observations that might exert disproportionate influence on the regression estimates. Three diagnostics were considered: Cook‚Äôs distance, leverage, and standardized residuals.

Cook‚Äôs distance: Observation 142 exceeds the recommended threshold, indicating it has a strong influence on the estimated coefficients.

Leverage values: Observations 110 and 126 have unusually high leverage, meaning their predictor values are extreme relative to the rest of the data.

Standardized residuals: Observation 142 has a residual beyond ¬±3, indicating a poor fit with the model predictions.

Overall, observation 142 appears to be the most influential point, both in terms of Cook‚Äôs distance and standardized residuals. Observations 110 and 126 also have high leverage, suggesting they could affect the model if not addressed. These points should be carefully examined to determine whether they represent data entry errors, extreme but valid values, or cases warranting model adjustment (e.g., exclusion or transformation) in a refined analysis.

#### Checking assumptions

Check the normality assumption.

```{r}
#### Checking assumptions: Normality of residuals

# Extract residuals
residuals_model <- residuals(model_complex)

# 1. Histogram
hist(residuals_model, breaks = 20, main = "Histogram of Residuals", xlab = "Residuals")

# 2. QQ plot
qqnorm(residuals_model, main = "QQ Plot of Residuals")
qqline(residuals_model, col = "red")

# 3. Shapiro-Wilk test
shapiro_test <- shapiro.test(residuals_model)
shapiro_test
```
Checking Normality of Residuals

The normality assumption of the residuals was assessed using a histogram, a QQ plot, and the Shapiro-Wilk test.

Histogram: The residuals show a distribution that deviates from the typical bell-shaped curve, suggesting non-normality.

QQ Plot: The residuals deviate substantially from the reference line, confirming that they are not normally distributed.

Shapiro-Wilk Test: W = 0.32303, p < 2.2e-16. The extremely low p-value indicates that the residuals significantly deviate from a normal distribution.

Interpretation:
The results suggest that the residuals of the complex model do not meet the normality assumption. This may be influenced by extreme outliers (e.g., observation 142 identified earlier).
Overall, these findings indicate that caution is needed when interpreting p-values and confidence intervals from this model, as the non-normality of residuals can affect their reliability.

Check the linearity assumption.

```{r}
library(car)

#### Checking assumptions: Linearity

# Residuals vs Fitted plot
plot(model_complex$fitted.values, residuals(model_complex),
     xlab = "Fitted values", ylab = "Residuals",
     main = "Residuals vs Fitted Values")
abline(h = 0, col = "red")

# Component + Residual plots
crPlots(model_complex)  # from the car package
```
Checking Linearity Assumption

The linearity assumption of the regression model was assessed using the Residuals vs Fitted Values plot and Component + Residual plots for each predictor.

Residuals vs Fitted plot: Most residuals are randomly scattered around the horizontal line, suggesting that the overall linearity assumption is reasonably met. However, there is one extreme residual above 40, indicating a strongly outlying observation (likely observation 142 identified previously).

Component + Residual observations by predictor:

Age: one outlier around 40 years.

Sex: female category has one high outlier above 40; male values remain close to 7.

STAI_trait: one extreme value around 44.

Pain_cat: one outlier around 30.

Cortisol_serum: one outlier around 6.

Cortisol_saliva: one outlier slightly above 6.

Mindfulness: one outlier around 3.

Weight: one outlier around 74.

IQ: one outlier slightly below 120.

Household_income: one outlier in the 7000‚Äì8000 range.

Interpretation:
Overall, the linearity assumption is largely satisfied, as the majority of residuals are randomly distributed around the zero line. However, the presence of multiple extreme values suggests that certain observations could disproportionately influence the regression estimates. These outliers should be carefully examined and may require consideration for model refinement, such as robust regression, transformation of variables, or exclusion if justified.

Check the homoscedasticty assumption (homogeneity of variance).

```{r}
#### Checking assumptions: Homoscedasticity

# 1. Residuals vs Fitted plot
plot(model_complex$fitted.values, residuals(model_complex),
     xlab = "Fitted values", ylab = "Residuals",
     main = "Residuals vs Fitted Values for Homoscedasticity")
abline(h = 0, col = "red")

# 2. Breusch-Pagan test
# install.packages("lmtest")  # ha m√©g nincs telep√≠tve
library(lmtest)
bptest(model_complex)
```
Checking Homoscedasticity (Homogeneity of Variance)

The homoscedasticity assumption, which requires that the residuals have constant variance across all levels of the fitted values, was assessed using a Residuals vs Fitted Values plot and the studentized Breusch-Pagan test.

Residuals vs Fitted plot: Most residuals are generally scattered evenly around the horizontal zero line, indicating constant variance. There is one outlying residual, but the overall pattern does not show a systematic funnel shape.

Breusch-Pagan test: BP = 4.9895, df = 10, p = 0.8919. The high p-value indicates no significant heteroscedasticity, confirming that the variance of residuals is approximately constant.

Interpretation:
The homoscedasticity assumption is satisfied for the complex model. This suggests that the standard errors, t-values, and confidence intervals are reliable. Although there is a single outlying point (likely observation 142 identified in previous diagnostic checks), it does not indicate a violation of the homoscedasticity assumption for the dataset overall.

Check the multicollinearity assumption.

(VIF above 5), or a VIF threshold of 3 is recommended in this paper: http://onlinelibrary.wiley.com/doi/10.1111/j.2041-210X.2009.00001.x/full

Some info about VIF: 
https://statisticalhorizons.com/multicollinearity
http://blog.minitab.com/blog/understanding-statistics/handling-multicollinearity-in-regression-analysis

```{r}
#### Checking assumptions: Multicollinearity

library(car)

# Calculate VIF for each predictor
vif_values <- vif(model_complex)
vif_values

# Optional: highlight predictors with VIF > 5
vif_values[vif_values > 5]
```
Checking Multicollinearity

Multicollinearity among predictors was assessed using the Variance Inflation Factor (VIF). A VIF value indicates how much the variance of a regression coefficient is inflated due to correlation with other predictors.

General interpretation of VIF values:

VIF < 3 ‚Üí negligible multicollinearity

VIF 3‚Äì5 ‚Üí moderate correlation

VIF > 5 ‚Üí potentially problematic multicollinearity

Results for the complex model:

Most predictors have VIF values below 3: age (1.55), sex (1.18), STAI_trait (2.20), pain_cat (1.98), mindfulness (1.62), weight (1.08), IQ (1.08), household_income (1.13).

Two predictors exceed the recommended threshold: cortisol_serum (6.20) and cortisol_saliva (6.80).

Interpretation:
The majority of predictors show no concerning multicollinearity. However, cortisol_serum and cortisol_saliva exhibit high VIF values, indicating that they are strongly correlated with other variables in the model. This may lead to unstable coefficient estimates and inflated standard errors for these predictors.

### Making decision based on model diagnostics

If based on the assumption tests you decide to drop a predictor variable you should do that here. Create your updated model.

```{r}
#### Updated model (dropping cortisol_saliva)

model_updated <- lm(
  pain ~ age + sex + STAI_trait + pain_cat + cortisol_serum +
    mindfulness + weight + IQ + household_income,
  data = data
)
summary(model_updated)
```
Updated Model Based on Diagnostics

Based on the model diagnostics, a decision was made to drop cortisol_saliva from the complex model in order to reduce multicollinearity. The updated model now includes: age, sex, STAI_trait, pain_cat, cortisol_serum, mindfulness, weight, IQ, and household_income.

Results of the updated model:

Residuals:
The residuals remain largely similar to the previous model, with a single extreme outlier (maximum ~43) persisting, likely corresponding to observation 142.

Coefficients:
                   Estimate Std. Error t value Pr(>|t|)  
(Intercept)      -4.096e+00  5.849e+00  -0.700   0.4848  
age              -2.063e-02  7.127e-02  -0.289   0.7726  
sexfemale         2.016e-01  6.558e-01   0.307   0.7590  
STAI_trait        1.659e-02  8.267e-02   0.201   0.8413  
pain_cat          7.095e-02  8.690e-02   0.816   0.4155  
cortisol_serum    8.133e-01  3.804e-01   2.138   0.0341 *
mindfulness      -4.965e-02  3.940e-01  -0.126   0.8999  
weight            1.470e-02  3.165e-02   0.464   0.6430  
IQ                2.407e-02  1.941e-02   1.240   0.2169  
household_income -7.495e-07  1.336e-05  -0.056   0.9553

Model fit:

Residual standard error: 3.814

Multiple R-squared: 0.0859

Adjusted R-squared: 0.0310

F-statistic: 1.565 on 9 and 150 DF, p = 0.1305

Interpretation:

The updated model shows that cortisol_serum is now the only significant predictor of pain (p = 0.0341).

The overall explained variance remains low (adjusted R¬≤ ~3%), suggesting that the model captures only a small proportion of the variability in pain.

The extreme outlier (likely observation 142) continues to influence the model and may affect residual distribution and coefficient estimates.

#### Checking outliers of the updated model

```{r}
#### Checking outliers for updated model

# Standardized residuals
std_resid <- rstandard(model_updated)

# Cook's distance
cooks_d <- cooks.distance(model_updated)

# Leverage
leverage_vals <- hatvalues(model_updated)

# Thresholds
n <- nrow(data)
p <- length(coef(model_updated)) - 1  # exclude intercept
cooksd_threshold <- 4/n
leverage_threshold <- 2*(p+1)/n

# Identify extreme points
extreme_resid <- which(abs(std_resid) > 3)
influential_cooks <- which(cooks_d > cooksd_threshold)
high_leverage <- which(leverage_vals > leverage_threshold)

# Print results
cat("Observations with extreme standardized residuals:", extreme_resid, "\n")
cat("Observations with high Cook's distance:", influential_cooks, "\n")
cat("Observations with high leverage:", high_leverage, "\n")
```
Checking Outliers in the Updated Model

Outliers and influential points in the updated model were examined using standardized residuals, Cook's distance, and leverage values.

Extreme standardized residuals: Observation 142 has a residual exceeding ¬±3, indicating a strong deviation from the model's predicted value.

Cook's distance: Observation 142 also shows a high Cook's distance, meaning it has a substantial influence on the regression coefficients.

Leverage values: Observations 32, 110, 126, and 160 have high leverage, indicating unusual combinations of predictor values that may affect the model fit.

Interpretation:

Observation 142 is a clear outlier and highly influential, consistent with previous diagnostics, and could distort coefficient estimates and residual patterns.

The high-leverage points (32, 110, 126, 160) are not extreme in residuals but may still impact the model due to their predictor values.

Overall, the majority of data points fit the model reasonably well, but attention should be paid to these identified points.

#### Checking assumptions of the updated model

Normality assumption

```{r}
#### Normality check for updated model

# Extract residuals
residuals_updated <- residuals(model_updated)

# 1. Q-Q plot
qqnorm(residuals_updated, main = "Q-Q Plot of Residuals (Updated Model)")
qqline(residuals_updated, col = "red")

# 2. Shapiro-Wilk test
shapiro.test(residuals_updated)
```
Checking Normality Assumption (Updated Model)

The normality of residuals in the updated model was assessed using a Q-Q plot and the Shapiro-Wilk test.

Q-Q plot: Residuals largely follow the reference line, indicating approximate normality. However, there is one extreme positive outlier at the high end, which deviates from the line.

Shapiro-Wilk test: W = 0.31996, p < 2.2e-16, indicating a significant deviation from normality. The extremely low p-value is primarily driven by the single high outlier.

Interpretation:

Overall, the residuals are approximately normal, but the extreme positive outlier (observation 142) strongly influences the formal test.

This outlier may affect t-values, p-values, and confidence intervals, so caution is advised in interpreting results.

Linearity assumption

```{r}
#### Linearity check for updated model

library(car)

# 1. Residuals vs Fitted plot
plot(model_updated$fitted.values, residuals(model_updated),
     xlab = "Fitted values", ylab = "Residuals",
     main = "Residuals vs Fitted Values (Updated Model)")
abline(h = 0, col = "red")

# 2. Component + Residual (partial residual) plots
crPlots(model_updated) 
```
Checking Linearity Assumption (Updated Model)

Linearity between the dependent variable and each predictor in the updated model was assessed using Residuals vs Fitted plots and Component + Residual (CR) plots.

Residuals vs Fitted plot: Most points are scattered around the horizontal line, indicating that the overall relationship between the fitted values and residuals is approximately linear.

CR plots: For each predictor, residuals generally follow a straight line, suggesting a linear relationship with the dependent variable.

Outlier: A single extreme observation (likely observation 142) appears in all plots, slightly deviating from the general trend.

Interpretation:

The linearity assumption is largely satisfied for the updated model.

The extreme outlier may affect the residual pattern and the regression coefficients, but it does not invalidate the overall linear relationships.

Handling the outlier (e.g., removal or robust regression) would likely make the linearity patterns even clearer.

Homoscedasticty assumption (homogeneity of variance)

```{r}
#### Homoscedasticity check for updated model

library(lmtest)

# Studentized Breusch-Pagan test
bptest(model_updated, studentize = TRUE)
```
Checking Homoscedasticity Assumption (Updated Model)

Homoscedasticity, or the assumption of equal variance of residuals across all levels of predictors, was assessed for the updated model using the Studentized Breusch-Pagan test and a Residuals vs Fitted plot.

Breusch-Pagan test: BP = 4.3203, df = 9, p = 0.8891. Since p > 0.05, the null hypothesis of constant variance is not rejected, indicating that homoscedasticity holds.

Residuals vs Fitted plot: The residuals are randomly scattered around the horizontal line at zero, with no apparent funnel or curved pattern, further confirming equal variance.

Interpretation:

The residuals exhibit homogeneous variance, satisfying the homoscedasticity assumption.

Despite the presence of the extreme outlier (observation 142), the overall variance of residuals is consistent across predicted values.

Multicollinearity assumption

```{r}
#### Multicollinearity check for updated model

library(car)

# Calculate VIF values
vif_values_updated <- vif(model_updated)
vif_values_updated

# Optional: highlight predictors with VIF > 5
vif_values_updated[vif_values_updated > 5]
```
Checking Multicollinearity Assumption (Updated Model)

Multicollinearity among predictors in the updated model was assessed using Variance Inflation Factor (VIF) values.

vif_values_updated
             age              sex       STAI_trait         pain_cat   cortisol_serum 
        1.412413         1.179796         1.981438         1.884237         1.554931 
     mindfulness           weight               IQ household_income 
        1.619854         1.078366         1.070490         1.114364 

No predictors have VIF > 5, indicating that multicollinearity is not a concern in this model.

Interpretation:

The predictors are not highly correlated with each other, and the regression coefficients are stable.

Previous multicollinearity issues related to cortisol_serum and cortisol_saliva have been resolved by removing cortisol_saliva from the model.

The updated model is stable and suitable for inference with respect to multicollinearity.

## Model comparison

Create the simple model and get the results of the model that needs to be reported based on the What to report section.

```{r}
# Simple model
model_simple <- lm(
  pain ~ age + sex + STAI_trait + pain_cat + mindfulness,
  data = data
)

summary(model_simple)

# AIC values
AIC(model_simple)

library(lm.beta)

# Standardized coefficients for simple model
model_simple_beta <- lm.beta(model_simple)
summary(model_simple_beta)

# Confidence intervals
confint(model_simple)
```
Simple Model Results

A simple linear regression model was fitted to predict pain from age, sex, STAI_trait, pain catastrophizing, and mindfulness.

Model fit statistics:

Residual standard error = 3.84 (df = 154)

Multiple R¬≤ = 0.0488

Adjusted R¬≤ = 0.0179

F(5, 154) = 1.58, p = 0.1688

These results indicate that the simple model explains only a small proportion of variance in pain, and the overall model is not statistically significant.

Coefficients:
             Estimate Standardized Std. Error t value Pr(>|t|)
(Intercept)  2.460681           NA   4.970069   0.495    0.621
age         -0.071704    -0.093336   0.067911  -1.056    0.293
sexfemale    0.217665     0.028142   0.646739   0.337    0.737
STAI_trait   0.076474     0.101653   0.077635   0.985    0.326
pain_cat     0.086968     0.107240   0.086689   1.003    0.317
mindfulness -0.038699    -0.009759   0.382391  -0.101    0.920

Interpretation:

None of the predictors reach statistical significance (p > 0.05).

Confidence intervals for all predictors include zero, suggesting no reliable effect in the sample.

Standardized coefficients indicate the largest, but still very small, effects are for pain catastrophizing (Beta = 0.107) and STAI_trait (Beta = 0.102).

Overall, the simple model has limited explanatory power for predicting pain.

Create the more complex model based on the results of the model diagnostics. Also, get the results that needs to be reported based on the What to report section.

\text{pain} = 2.461 + (-0.0717 \cdot \text{age}) + 0.218 \cdot \text{sexfemale} + 0.0765 \cdot \text{STAI_trait} + 0.0870 \cdot \text{pain_cat} + (-0.0387 \cdot \text{mindfulness})

```{r}
# Complex (updated) model
model_updated <- lm(
  pain ~ age + sex + STAI_trait + pain_cat + cortisol_serum +
         mindfulness + weight + IQ + household_income,
  data = data
)

summary(model_updated)

# 95% confidence intervals
confint(model_updated)

# Standardized coefficients using scale()
model_updated_std <- lm(
  scale(pain) ~ scale(age) + scale(as.numeric(sex)) + scale(STAI_trait) +
                 scale(pain_cat) + scale(cortisol_serum) + scale(mindfulness) +
                 scale(weight) + scale(IQ) + scale(household_income),
  data = data
)

summary(model_updated_std)
AIC(model_updated)
```

Complex (Updated) Model Results

A complex linear regression model was fitted to predict pain from age, sex, STAI_trait, pain catastrophizing, cortisol_serum, mindfulness, weight, IQ, and household_income. The model was adjusted based on diagnostics, removing problematic predictors (e.g., cortisol_saliva) to satisfy regression assumptions.

Model fit statistics:

Residual standard error = 0.9844 (df = 150)

Multiple R¬≤ = 0.0859

Adjusted R¬≤ = 0.0310

F(9, 150) = 1.565, p = 0.1305

AIC = 894.12

The model explains a small proportion of variance in pain (adj. R¬≤ = 0.031) and is not statistically significant overall (p = 0.1305).

Standardized regression coefficients (Beta) and unstandardized coefficients (B) with p-values:

Predictor	B (unstandardized)	Beta (standardized)	p-value
(Intercept)	2.045e-16	NA	1.000
age	-0.0269	-0.027	0.773
sexfemale	0.0261	0.026	0.759
STAI_trait	0.0221	0.022	0.841
pain_cat	0.0875	0.087	0.415
cortisol_serum	0.2081	0.208	0.034 *
mindfulness	-0.0125	-0.013	0.900
weight	0.0377	0.038	0.643
IQ	0.1002	0.100	0.217
household_income	-0.0046	-0.005	0.955

Interpretation:

Only cortisol_serum shows a statistically significant association with pain (p = 0.034).

All other predictors are non-significant (p > 0.05).

The standardized coefficients indicate cortisol_serum has the largest relative effect among predictors.

Overall, the complex model explains slightly more variance than the simple model (adj. R¬≤ = 0.031 vs. 0.018), but the improvement is not statistically significant.

Regression equation (unstandardized coefficients):

\text{pain} = 2.045 \times 10^{-16} + (-0.0269 \cdot \text{age}) + 0.0261 \cdot \text{sexfemale} + 0.0221 \cdot \text{STAI_trait} + 0.0875 \cdot \text{pain_cat} + 0.2081 \cdot \text{cortisol_serum} + (-0.0125 \cdot \text{mindfulness}) + 0.0377 \cdot \text{weight} + 0.1002 \cdot \text{IQ} + (-0.0046 \cdot \text{household_income})

Compare the two models.

```{r}
AIC(model_simple)
AIC(model_updated)

anova(model_simple, model_updated)
```
Model Comparison: Simple vs. Complex (Updated) Model

To evaluate whether the more complex model provides a better fit to the data than the simpler model, we compared the models in terms of variance explained, Akaike Information Criterion (AIC), and a likelihood ratio (F) test.

Model fit statistics:

Model	Adjusted R¬≤	AIC	Residual df	Residual Sum of Squares (RSS)
Simple	0.0179	898.22	154	2270.5
Complex	0.0310	894.12	150	2182.0

The complex model explains slightly more variance in pain (adj. R¬≤ = 0.031) than the simple model (adj. R¬≤ = 0.018).

The AIC is lower for the complex model (894.12 vs. 898.22), indicating a marginally better fit.

Nested model comparison (F-test):

F(4, 150) = 1.5203, p = 0.1991

Since p > 0.05, the difference between models is not statistically significant, meaning the complex model does not provide a significantly better overall fit than the simple model.

Interpretation:

While the complex model includes additional predictors such as cortisol_serum, which has a statistically significant effect on pain (p = 0.034), the overall improvement in model fit is modest.

The simple model remains largely comparable in explanatory power, and the added complexity does not significantly enhance prediction of pain in this sample.

Conclusion:

The complex model may be preferred if interest lies in individual predictors like cortisol_serum.

However, for overall model fit and parsimony, the simpler model performs similarly to the complex model.
